package utils

import com.typesafe.config.{Config, ConfigFactory}
import constants.AppConstants.{APP_MASTER, APP_NAME}
import org.apache.spark.sql.types.{DataType, StructType}
import org.apache.spark.sql.SparkSession

import java.io.File
import scala.io.Source

object AppUtils {
  //configuration
  def configuration(inputPath: String): Config = {
    val parsedConfig = ConfigFactory.parseFile(new File(inputPath))
    val appConf: Config = ConfigFactory.load(parsedConfig)
    appConf
  }

  //Creating the spark session
  def createSparkSession(inputAppConf: Config): SparkSession = {
    implicit val spark: SparkSession = SparkSession.getActiveSession.getOrElse(
      SparkSession.builder
        .appName(inputAppConf.getString(APP_NAME))
        .master(inputAppConf.getString(APP_MASTER))
        .getOrCreate()
    )
    spark
  }

  //to extract the schema from the json file
  def schemaRead(schemaPath : String) : StructType = {
    val source = Source.fromFile(schemaPath)
    val schemaJson = try source.getLines().mkString finally source.close()
    val correctSchema = DataType.fromJson(schemaJson).asInstanceOf[StructType]
    correctSchema
  }

}

package businessLogic

import constants.AppConstants.ERROR_TABLE
import org.apache.spark.sql.functions.col
import org.apache.spark.sql.{DataFrame, functions}
import service.DatabaseConnection.FileWriter

object BusinessLogic {

      //remove invalid selling channels from the dataframe
      def sellingChannelValidator(inputDF:DataFrame,tableName:String): DataFrame ={
        val errorDF= inputDF.filter((inputDF("selling_channel")=!="Cross Over" && inputDF("selling_channel")=!="Store Only"  && inputDF("selling_channel")=!="Online Only"))
        FileWriter(errorDF, ERROR_TABLE, "append")
        val validSellingChannelDF = inputDF.except(errorDF)
        validSellingChannelDF
      }

      //remove invalid price values such as 0 and nulls from the retail price
      def retailPriceValidator(inputDF:DataFrame,tableName:String): DataFrame ={
        val errorDF = inputDF.filter(inputDF("retail_price")===0 || inputDF("retail_price").isNull)
        FileWriter(errorDF, ERROR_TABLE, "append")
        val validRetailPriceDF = inputDF.except(errorDF)
        validRetailPriceDF
      }

      def productIdValidator(inputDF:DataFrame,tableName:String): DataFrame ={
        val numericDF = inputDF.filter(col("product_id").cast("int").isNotNull)
        val validProductIdDF = numericDF.filter(functions.length(col("product_id")) === 8)
        val errorDF = inputDF.except(validProductIdDF)
        FileWriter(errorDF, ERROR_TABLE, "append")
        validProductIdDF
      }


  }
